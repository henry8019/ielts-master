"use server"

import OpenAI from "openai"

const openai = new OpenAI({
  baseURL: process.env.DEEPSEEK_BASE_URL,
  apiKey: process.env.DEEPSEEK_API_KEY,
})

// 1. ç°æœ‰çš„ Copilot åŠŸèƒ½ (ä¿æŒä¸å˜ï¼Œç•¥å¾®ç²¾ç®€)
export async function askAI(questionContent: string, taskType: string, intent: string) {
    // ... (ä¿æŒä½ ä¹‹å‰çš„ä»£ç é€»è¾‘ï¼Œä¸ºäº†èŠ‚çœç¯‡å¹…è¿™é‡Œçœç•¥ï¼Œé‡ç‚¹æ˜¯ä¸‹é¢æ–°å¢çš„)
    // å¦‚æœä½ ä¹‹å‰çš„ä»£ç ä¸¢äº†ï¼Œå‘Šè¯‰æˆ‘ï¼Œæˆ‘å†å‘ä¸€éå®Œæ•´ç‰ˆ
    let systemPrompt = ""
    switch (intent) {
        case "analyze": systemPrompt = "ä½ æ˜¯ä¸€ä½é›…æ€å†™ä½œè€ƒå®˜ã€‚è¯·åˆ†æé¢˜ç›®..."; break;
        case "outline": systemPrompt = "ä½ æ˜¯ä¸€ä½é›…æ€å†™ä½œå¯¼å¸ˆã€‚è¯·æä¾›é«˜åˆ†ç»“æ„æ¨¡æ¿..."; break;
        case "ideas": systemPrompt = "è¯·æä¾›Brainstormingç´ æ..."; break;
        case "vocab": systemPrompt = "è¯·æ¨èC1/C2é«˜çº§è¯æ±‡ï¼Œè¿”å›JSONæ ¼å¼..."; break;
    }
    // ... fetch logic
    const completion = await openai.chat.completions.create({
        messages: [{ role: "system", content: systemPrompt }, { role: "user", content: `é¢˜ç›®ï¼š${questionContent}` }],
        model: "deepseek-chat",
    })
    return { success: true, data: completion.choices[0].message.content }
}

// ğŸ†• 2. AI å‡ºé¢˜åŠŸèƒ½
export async function generateQuestionAction(type: 'task1' | 'task2', topic?: string) {
  const prompt = topic 
    ? `è¯·ç”Ÿæˆä¸€é“é›…æ€Gç±»å†™ä½œ ${type === 'task1' ? 'ä¹¦ä¿¡' : 'å¤§ä½œæ–‡'} é¢˜ç›®ï¼Œè¯é¢˜å…³äº "${topic}"ã€‚`
    : `è¯·éšæœºç”Ÿæˆä¸€é“æ ‡å‡†çš„é›…æ€Gç±»å†™ä½œ ${type === 'task1' ? 'ä¹¦ä¿¡' : 'å¤§ä½œæ–‡'} çœŸé¢˜ã€‚`

  const system = `ä½ æ˜¯ä¸€ä¸ªé›…æ€å‡ºé¢˜å®˜ã€‚è¯·ç›´æ¥è¿”å›é¢˜ç›®å†…å®¹ï¼Œæ ¼å¼è¦æ±‚ JSONï¼š
  {
    "title": "ç®€çŸ­æ ‡é¢˜",
    "content": "å®Œæ•´çš„é¢˜ç›®æè¿°ï¼ŒåŒ…å« bullet points",
    "type": "${type}"
  }
  åªè¿”å› JSONï¼Œä¸è¦ Markdownã€‚`

  try {
    const res = await openai.chat.completions.create({
      messages: [{ role: "system", content: system }, { role: "user", content: prompt }],
      model: "deepseek-chat",
      response_format: { type: "json_object" } 
    })
    return { success: true, data: JSON.parse(res.choices[0].message.content || "{}") }
  } catch (e) {
    return { success: false, error: "AI Failed to generate question" }
  }
}

// ğŸ†• 3. AI æ‰¹æ”¹åŠŸèƒ½
export async function gradeEssayAction(question: string, essay: string) {
  const system = `ä½ æ˜¯ä¸€ä½é›…æ€å‰è€ƒå®˜ã€‚è¯·æ ¹æ® TR, CC, LR, GRA å››é¡¹æ ‡å‡†å¯¹ç”¨æˆ·çš„ä½œæ–‡è¿›è¡Œæ‰“åˆ†ã€‚
  è¯·è¿”å› JSON æ ¼å¼ï¼š
  {
    "overall_score": "6.5",
    "breakdown": { "TR": 6, "CC": 7, "LR": 6, "GRA": 7 },
    "feedback": "ç®€çŸ­çš„æ•´ä½“è¯„ä»·...",
    "suggestions": ["å»ºè®®1", "å»ºè®®2"]
  }`

  try {
    const res = await openai.chat.completions.create({
      messages: [
        { role: "system", content: system },
        { role: "user", content: `é¢˜ç›®ï¼š${question}\n\nè€ƒç”Ÿä½œæ–‡ï¼š${essay}` }
      ],
      model: "deepseek-chat",
      response_format: { type: "json_object" }
    })
    return { success: true, data: JSON.parse(res.choices[0].message.content || "{}") }
  } catch (e) {
    return { success: false, error: "Grading failed" }
  }
}

export async function generateSampleAction(question: string) {
  try {
    const res = await openai.chat.completions.create({
      messages: [
        { 
            role: "system", 
            content: "ä½ æ˜¯ä¸€ä½é›…æ€8åˆ†è€ƒç”Ÿã€‚è¯·é’ˆå¯¹è¯¥é¢˜ç›®å†™ä¸€ç¯‡æ»¡åˆ†èŒƒæ–‡ã€‚ç›´æ¥è¿”å›æ–‡ç« å†…å®¹ã€‚Keep it concise and high-quality." 
        },
        { role: "user", content: question }
      ],
      model: "deepseek-chat",
      max_tokens: 500 
    })
    return { success: true, data: res.choices[0].message.content }
  } catch (e) {
    return { success: false, error: "Sample gen failed" }
  }
}